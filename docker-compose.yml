version: "3.8"

x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: Dockerfile.airflow
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CORE__FERNET_KEY: 'YOUR_FERNET_KEY'
    AIRFLOW__WEBSERVER__SECRET_KEY: 'your-very-secret-key'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'True'
    _PIP_ADDITIONAL_REQUIREMENTS: ""
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
  depends_on:
    postgres:
      condition: service_healthy

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://34.16.77.121:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
    ports:
      - "9094:9094"

  jobmanager:
    build:
      context: .
      dockerfile: Dockerfile  # Your existing Flink Dockerfile
    image: flink-with-connectors:1.18.1
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    ports:
      - "8081:8081"

  taskmanager:
    build:
      context: .
      dockerfile: Dockerfile
    image: flink-with-connectors:1.18.1
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager

  airflow-webserver:
    <<: *airflow-common
    command: >
      bash -c "airflow db upgrade &&
               airflow users create --username airflow --password airflow --firstname Admin --lastname User --role Admin --email admin@example.com &&
               airflow webserver --port 8080 --host 0.0.0.0"
    ports:
      - "8080:8080"

  airflow-scheduler:
    <<: *airflow-common
    command: airflow scheduler

volumes:
  postgres_data:
